{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645e8b52-e604-4853-9e6c-7845bf56d175",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      9\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m/Users/lucija/Projects/Analisis-de-noticias/src/utils\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtext_processing\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(text_processing.\u001b[34m__file__\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asignar_provincia_comunidad\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Analisis-de-noticias/src/02.Preprocesamiento/../utils/text_processing.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprovincias_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PROVINCIAS_COMUNIDADES\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masignar_provincia_comunidad\u001b[39m(df):\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    Assigns 'provincia' and 'comunidad' based on the 'title' and 'content' columns.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    If 'Desconocido' is assigned, it replaces it with NaN.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33;03m        pd.DataFrame: The updated DataFrame with 'provincia' and 'comunidad' columns.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/lucija/Projects/Analisis-de-noticias/src/utils\")\n",
    "\n",
    "import text_processing\n",
    "print(text_processing.__file__)\n",
    "\n",
    "from utils.text_processing import asignar_provincia_comunidad\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfcd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../00.data/scraped\"\n",
    "\n",
    "csv_files = sorted(glob.glob(os.path.join(folder_path, \"*.csv\")), key=os.path.getmtime)\n",
    "\n",
    "df_list = [pd.read_csv(file) for file in csv_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0572a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d28291eb-59a1-4462-870e-0f9278c3f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"news_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1a383-98ac-4015-be6a-543b7d36230f",
   "metadata": {},
   "source": [
    "# Procesamiento de 'comunidad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41b53ec2-4c98-47cc-8595-8aadd7a17e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de provincias-ccaa\n",
    "PROVINCIAS_COMUNIDADES = {\n",
    "    \"Andalucía\": {\n",
    "        \"provincias\": [\"Almería\", \"Cádiz\", \"Córdoba\", \"Granada\", \"Huelva\", \"Jaén\", \"Málaga\", \"Sevilla\"]\n",
    "    },\n",
    "    \"Aragón\": {\n",
    "        \"provincias\": [\"Huesca\", \"Teruel\", \"Zaragoza\"]\n",
    "    },\n",
    "    \"Asturias\": {\n",
    "        \"provincias\": [\"Asturias\"]\n",
    "    },\n",
    "    \"Islas Baleares\": {\n",
    "        \"provincias\": [\"Illes Balears\"],\n",
    "        \"equivalencias\": {\n",
    "            \"Mallorca\": \"Illes Balears\",\n",
    "            \"Menorca\": \"Illes Balears\",\n",
    "            \"Cabrera\": \"Illes Balears\",\n",
    "            \"Ibiza\": \"Illes Balears\",\n",
    "            \"Formentera\": \"Illes Balears\"\n",
    "        }\n",
    "    },\n",
    "    \"Canarias\": {\n",
    "        \"provincias\": [\"Las Palmas\", \"Santa Cruz de Tenerife\"],\n",
    "        \"equivalencias\": {\n",
    "            \"Gran Canaria\": \"Las Palmas\",\n",
    "            \"Lanzarote\": \"Las Palmas\",\n",
    "            \"Fuerteventura\": \"Las Palmas\",\n",
    "            \"La Graciosa\": \"Las Palmas\",\n",
    "            \"Tenerife\": \"Santa Cruz de Tenerife\",\n",
    "            \"La Gomera\": \"Santa Cruz de Tenerife\",\n",
    "            \"El Hierro\": \"Santa Cruz de Tenerife\",\n",
    "            \"La Palma\": \"Santa Cruz de Tenerife\"\n",
    "        }\n",
    "    },\n",
    "    \"Cantabria\": {\n",
    "        \"provincias\": [\"Cantabria\"]\n",
    "    },\n",
    "    \"Castilla La Mancha\": {\n",
    "        \"provincias\": [\"Albacete\", \"Ciudad Real\", \"Cuenca\", \"Guadalajara\", \"Toledo\"]\n",
    "    },\n",
    "    \"Castilla y León\": {\n",
    "        \"provincias\": [\"Ávila\", \"Burgos\", \"León\", \"Palencia\", \"Salamanca\", \"Segovia\", \"Soria\", \"Valladolid\", \"Zamora\"]\n",
    "    },\n",
    "    \"Cataluña\": {\n",
    "        \"provincias\": [\"Barcelona\", \"Girona\", \"Lleida\", \"Tarragona\"],\n",
    "        \"equivalencias\": {\n",
    "            \"Gerona\": \"Girona\",\n",
    "            \"Lérida\": \"Lleida\"\n",
    "        }\n",
    "    },\n",
    "    \"Extremadura\": {\n",
    "        \"provincias\": [\"Badajoz\", \"Cáceres\"]\n",
    "    },\n",
    "    \"Galicia\": {\n",
    "        \"provincias\": [\"A Coruña\", \"Lugo\", \"Ourense\", \"Pontevedra\"],\n",
    "        \"equivalencias\": {\n",
    "            \"Coruña\": \"A Coruña\"\n",
    "        }\n",
    "    },\n",
    "    \"Madrid\": {\n",
    "        \"provincias\": [\"Madrid\"]\n",
    "    },\n",
    "    \"Murcia\": {\n",
    "        \"provincias\": [\"Murcia\"]\n",
    "    },\n",
    "    \"Navarra\": {\n",
    "        \"provincias\": [\"Navarra\"]\n",
    "    },\n",
    "    \"La Rioja\": {\n",
    "        \"provincias\": [\"La Rioja\"]\n",
    "    },\n",
    "    \"País Vasco\": {\n",
    "        \"provincias\": [\"Araba/Álava\", \"Bizkaia/Vizcaya\", \"Gipuzkoa/Guipúzcoa\"],\n",
    "        \"equivalencias\": {\n",
    "            \"Araba\": \"Araba/Álava\",\n",
    "            \"Álava\": \"Araba/Álava\",\n",
    "            \"Bizkaia\": \"Bizkaia/Vizcaya\",\n",
    "            \"Vizcaya\": \"Bizkaia/Vizcaya\",\n",
    "            \"Gipuzkoa\": \"Gipuzkoa/Guipúzcoa\",\n",
    "            \"Guipúzcoa\": \"Gipuzkoa/Guipúzcoa\"\n",
    "        }\n",
    "    },\n",
    "    \"Comunidad Valenciana\": {\n",
    "        \"provincias\": [\"Alacant/Alicante\", \"Castelló/Castellón\", \"València/Valencia\"],\n",
    "        \"equivalencias\": {\n",
    "            \"Alicante\": \"Alacant/Alicante\",\n",
    "            \"Alacant\": \"Alacant/Alicante\",\n",
    "            \"Castellón\": \"Castelló/Castellón\",\n",
    "            \"Castelló\": \"Castelló/Castellón\",\n",
    "            \"Valencia\": \"València/Valencia\",\n",
    "            \"València\": \"València/Valencia\"\n",
    "        }\n",
    "    },\n",
    "    \"Ceuta\": {\n",
    "        \"provincias\": [\"Ceuta\"]\n",
    "    },\n",
    "    \"Melilla\": {\n",
    "        \"provincias\": [\"Melilla\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8080c989-638e-47b6-9cdc-47e1849b9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignar_provincia_comunidad(row):\n",
    "    title = str(row[\"title\"]) if pd.notna(row[\"title\"]) else \"\"\n",
    "    content = str(row[\"content\"]) if pd.notna(row[\"content\"]) else \"\"\n",
    "    \n",
    "    for comunidad, datos in PROVINCIAS_COMUNIDADES.items():\n",
    "        provincias = datos[\"provincias\"]\n",
    "        equivalencias = datos.get(\"equivalencias\", {})\n",
    "        \n",
    "        for provincia in provincias:\n",
    "            if provincia in title or provincia in content:\n",
    "                return {\"provincia\": provincia, \"comunidad\": comunidad}\n",
    "        \n",
    "        for variante, provincia_estandar in equivalencias.items():\n",
    "            if variante in title or variante in content:\n",
    "                return {\"provincia\": provincia_estandar, \"comunidad\": comunidad}\n",
    "\n",
    "    return {\"provincia\": \"Desconocido\", \"comunidad\": \"Desconocido\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "198d4496-9216-4d0d-9e19-be55224b0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función fila por fila\n",
    "df.loc[:, [\"provincia\", \"comunidad\"]] = df.apply(asignar_provincia_comunidad, axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c56508f-738f-4575-8d81-626c81f41452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/dfk_lr0j0pg5th31583lwbxc0000gn/T/ipykernel_81017/470152133.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['comunidad'] = df['comunidad'].replace('Desconocido', np.nan)\n",
      "/var/folders/x1/dfk_lr0j0pg5th31583lwbxc0000gn/T/ipykernel_81017/470152133.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['provincia'] = df['provincia'].replace('Desconocido', np.nan)\n"
     ]
    }
   ],
   "source": [
    "df['comunidad'] = df['comunidad'].replace('Desconocido', np.nan)\n",
    "\n",
    "df['provincia'] = df['provincia'].replace('Desconocido', np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3873a-bfcf-41d8-8d7e-046343dbf17d",
   "metadata": {},
   "source": [
    "# Procesamiento de Categorias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ebe581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_category_map = {\n",
    "    \"Política y Sociedad\": [\"EEUU\", \"Rusia\", \"INTERNAC\", \"OrienteMedio\", \"politica\", \"corruPPción\", \"corruptcion\", \"corrupcion\", \"EleccionesE\", \"Podemos\", \"República\", \"RentaBásica\", \"Cayetanos\", \"LuchaDClases\", \"Anarquismo\", \"DDHH\", \"Autonomos\", \"Justicia7291\", \"Tribunales\", \"actualidad\", \"ZasSmeame\", \"Campañas\", \"Fachéame\", \"prensa\", \"borbones\", \"KKKantiPDMS\", \"AEDE\", \"procescatalà\", \"RebeliónMnm\", \"DchoLaboral\", \"Bulos\", \"Desinfórmame\", \"Madriléame\", \"Begoñéame\", \"Palestina\", \"Israel\", \"Siria\", \"GuerraCivilñ\", \"ayudaucrania\", \"Rescates\"],\n",
    "    \"Tecnología y Ciencia\": [\"tecnología\", \"Informática\", \"GNU_LINUX\", \"linux\", \"SectorTIC\", \"Meteorología\", \"Física\", \"genetica\", \"Neurociencia\", \"Debian\", \"retrocomp\", \"hacking\", \"Metamaterial\", \"Micromundo\", \"atomo\", \"Impresión3D\", \"Drones\", \"netsec\", \"RaspberryPi\", \"SysDevs\", \"ciencia\", \"astronomia\", \"ASTRONÁUTICA\", \"softlibre\", \"Ubuntu\", \"android\", \"smartphone\", \"Firefox\", \"IOOcia\", \"Marte\", \"Visualdata\", \"INVENTOS\", \"Numismática\", \"FÓSILES\"],\n",
    "    \"Salud y Medicina\": [\"salud\", \"medicina\", \"Nutrición\", \"sanidad\", \"PREVENCIÓN\", \"HOMEOPATÍA\", \"VacunaGate\", \"vacúname\", \"SANIDAD\", \"Alimentación\", \"ebola\", \"Coronavirus\"],\n",
    "    \"Negocios y Economía\": [\"Criptomoneda\",\"startup\", \"bitcoin\" \"Economía\", \"banca\", \"subvenciones\", \"CrisEnergéti\"],\n",
    "    \"Entretenimiento y Cultura\": [\"ocio\", \"Cine\", \"Series\", \"Videojuegos\", \"Fotografía\", \"Música\", \"cinéfilos\", \"FolkloreÑ\", \"Cómics\", \"Webcomics\", \"ArteyMercado\", \"Arte\", \"Ilustracion\", \"clásica\", \"Covers\", \"cultura\", \"Eurovision\", \"Poesia\", \"Bushido\", \"Arquitectura\", \"Podcasteros\", \"Viajar\", \"CiFi\", \"Gastronomia\", \"Clicómics\", \"acapela\", \"museo\", \"Relatocorto\", \"Autorrelatos\", \"Reportajes\", \"Entrevistas\", \"microrelatos\", \"Recomiéndame\", \"LETREROS\", \"Documentales\", \"STARWARS\", \"B.S.O.\", \"Fotomundo\", \"TEMAZOS\", \"Comiñas\", \"MundoCelta\", \"Artículos\"],\n",
    "    \"Deportes\": [\"deportes\", \"Natación\", \"Motociclismo\", \"ciclismo\"],\n",
    "    \"Medioambiente y Energía\": [\"veganismo\", \"MenteAnimal\", \"Abandonos\", \"MUNDO_PROTE\", \"MAmbiente\", \"Cambioclima\", \"Ecología\", \"Energias\", \"sequía\", \"Naturaleza\", \"Botánica\", \"PLANTAS\", \"AgroInfo\", \"Vivienda\", \"Animales\", \"gatos\", \"Biologia\", \"Faros\", \"mascotas\", \"Cáñamo\", \"Arañas\"],\n",
    "    \"Historia y Humanidades\": [\"Historia\", \"Mitología\", \"Arqueología\", \"Egiptologia\", \"Viñetas\", \"Hallazgos\", \"Asturias\", \"Jurídicas\", \"Etimologia\", \"Psicología\", \"Psicópatas\", \"Filosofía\", \"Efemérides\", \"Helénica\", \"Hemeroteca\", \"Fragmentos\"],\n",
    "    \"Humor y Memes\": [\"Humor\", \"Los12monos\", \"memes\", \"Sarcasmos\", \"Chorridolias\", \"Tendenciosos\", \"Ayuséame\", \"podríame\", \"Fakeame\", \"Fakejóo\", \"Idiocracia\", \"meneametoday\", \"TuMeme\", \"Cosasguays\", \"friki\", \"procrastrina\", \"NoMundoToday\", \"Memeneame\", \"Ardilléame\", \"Toréame\", \"OYOYOY\", \"gilipolleces\", \"chorradas\"],\n",
    "    \"Transporte\": [\"aviacion\", \"aviones\", \"trenes\", \"DIRIGIBLES\", \"Submarino\", \"Motor\", \"Avionéame\", \"BARCOS\", \"Tractores\", \"movilidad\", \"alas\"],\n",
    "    \"Educación\": [\"Educación\", \"idiomas\", \"Enseñanza\", \"Literatura\", \"Libros\", \"lenguas\", \"Matemáticas\"],\n",
    "    \"Crimen\": [\"INV\",\"VIOLENCIA_G\", \"Gamonal\", \"Sectas\", \"Sucesos\"],\n",
    "    \"Cuestiones Sociales\": [\"Asperger\", \"Crianza\", \"Drogolegas\", \"Feminismo\", \"LGBT\", \"Derecho\", \"SEXOLOGÍA\", \"mujeresenlah\", \"Abuso_Animal\", \"religion\", \"laicismo\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2799f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/dfk_lr0j0pg5th31583lwbxc0000gn/T/ipykernel_81017/3119110777.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"category\"] = df[\"category\"].apply(map_category)\n"
     ]
    }
   ],
   "source": [
    "category_lookup = {word.lower(): category for category, words in news_category_map.items() for word in words}\n",
    "\n",
    "# Function to map category names\n",
    "def map_category(category):\n",
    "    return category_lookup.get(category.lower(), \"Otros\")\n",
    "\n",
    "# Apply mapping\n",
    "df[\"category\"] = df[\"category\"].apply(map_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "184f5053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Otros                        135107\n",
       "Política y Sociedad           95400\n",
       "Entretenimiento y Cultura     40224\n",
       "Tecnología y Ciencia          14523\n",
       "Deportes                        632\n",
       "Historia y Humanidades          294\n",
       "Crimen                          254\n",
       "Negocios y Economía             246\n",
       "Humor y Memes                   246\n",
       "Transporte                      221\n",
       "Medioambiente y Energía         200\n",
       "Salud y Medicina                137\n",
       "Cuestiones Sociales              69\n",
       "Educación                        27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c57878be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscando mas instancias de noticias de las categorias subrepresentadas\n",
    "\n",
    "df.loc[(df['category']=='Otros') & (df['content'].str.contains('fútbol', case=False, na=False)), 'category'] = 'Deportes'\n",
    "df.loc[(df['category']=='Otros') & (df['content'].str.contains('crim', case=False, na=False)) & (df['content'].str.contains('polic', case=False, na=False)), 'category'] = 'Crimen'\n",
    "df.loc[(df['category']=='Otros') & (df['content'].str.contains('econom', case=False, na=False)) & (df['content'].str.contains('financ', case=False, na=False)), 'category'] = 'Negocios y Economía'\n",
    "df.loc[(df['category']=='Otros') & (df['content'].str.contains('escuela', case=False, na=False)) & (df['content'].str.contains('currícu', case=False, na=False)), 'category'] = 'Educación'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274e009",
   "metadata": {},
   "source": [
    "### categorisando \"otros\" usando ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa077f65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# GridSearchCV\u001b[39;00m\n\u001b[32m     14\u001b[39m grid_search = GridSearchCV(rf, param_grid, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m\"\u001b[39m\u001b[33mf1_weighted\u001b[39m\u001b[33m\"\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m grid_search.fit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest Parameters:\u001b[39m\u001b[33m\"\u001b[39m, grid_search.best_params_)\n\u001b[32m     19\u001b[39m best_rf = grid_search.best_estimator_\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],  # Number of trees\n",
    "    \"max_depth\": [None, 10, 20, 30],  # Depth of trees\n",
    "    \"min_samples_split\": [2, 5, 10],  # Minimum samples to split a node\n",
    "    \"min_samples_leaf\": [1, 2, 4],  # Minimum samples in a leaf\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],  # Number of features per split\n",
    "    \"bootstrap\": [True, False]  # Use bootstrap sampling?\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96978645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lucija/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/x1/dfk_lr0j0pg5th31583lwbxc0000gn/T/ipykernel_81017/2146132223.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labeled[\"category_encoded\"] = label_encoder.fit_transform(df_labeled[\"category\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Sampling: Counter({9: 95400, 4: 40217, 11: 14522, 2: 632, 5: 294, 0: 254, 8: 246, 6: 240, 12: 221, 7: 200, 10: 137, 1: 69, 3: 27})\n",
      "After Sampling: Counter({4: 3000, 9: 3000, 11: 3000, 0: 1000, 2: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 12: 1000, 1: 800, 3: 800, 10: 800})\n",
      "Model Accuracy: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       200\n",
      "           1       1.00      0.98      0.99       160\n",
      "           2       0.98      0.84      0.91       200\n",
      "           3       1.00      1.00      1.00       160\n",
      "           4       0.63      0.62      0.63       600\n",
      "           5       0.99      0.92      0.96       200\n",
      "           6       0.86      0.94      0.90       200\n",
      "           7       1.00      0.99      0.99       200\n",
      "           8       0.99      0.98      0.98       200\n",
      "           9       0.71      0.76      0.74       600\n",
      "          10       0.99      0.97      0.98       160\n",
      "          11       0.71      0.74      0.72       600\n",
      "          12       0.99      0.98      0.98       200\n",
      "\n",
      "    accuracy                           0.83      3680\n",
      "   macro avg       0.91      0.90      0.90      3680\n",
      "weighted avg       0.84      0.83      0.83      3680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "spanish_stopwords = stopwords.words(\"spanish\")\n",
    "\n",
    "df = df.dropna(subset=[\"content\"])\n",
    "\n",
    "df_unlabeled = df[df['category'] == \"Otros\"]\n",
    "df_labeled = df[df['category'] != \"Otros\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_labeled[\"category_encoded\"] = label_encoder.fit_transform(df_labeled[\"category\"])\n",
    "\n",
    "X = df_labeled[\"content\"] \n",
    "y = df_labeled[\"category_encoded\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=spanish_stopwords, max_features=50000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"Before Sampling:\", Counter(y))\n",
    "\n",
    "# combinacion de under y oversampling\n",
    "undersampling_strategy = {9: 3000, 4: 3000, 11: 3000}\n",
    "oversampling_strategy = {5: 1000, 6: 1000, 12: 1000, 7: 1000, 10: 800, \n",
    "                         0: 1000, 1: 800, 8: 1000, 3: 800, 2: 1000}  \n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy=undersampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_tfidf, y)\n",
    "\n",
    "oversampler = SMOTE(sampling_strategy=oversampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "print(\"After Sampling:\", Counter(y_resampled))\n",
    "\n",
    "df_balanced = pd.DataFrame({\"category\": label_encoder.inverse_transform(y_resampled)})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# usamos Random Forest classifier para entrenar el modelo\n",
    "model = RandomForestClassifier(\n",
    "    bootstrap=False, \n",
    "    max_depth=None, \n",
    "    max_features='log2', \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=5, \n",
    "    n_estimators=300, \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56625700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/dfk_lr0j0pg5th31583lwbxc0000gn/T/ipykernel_81017/2067863714.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unlabeled[\"category\"] = final_categories\n"
     ]
    }
   ],
   "source": [
    "X_unlabeled = vectorizer.transform(df_unlabeled[\"content\"])\n",
    "\n",
    "y_proba = model.predict_proba(X_unlabeled)\n",
    "\n",
    "max_probs = np.max(y_proba, axis=1)\n",
    "\n",
    "y_pred_indices = np.argmax(y_proba, axis=1)\n",
    "\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_indices)\n",
    "\n",
    "#si modelo esta <30% cierto sobre la categorisacion, lo clasifica como \"otros\"\n",
    "final_categories = np.where(max_probs >= 0.30, y_pred_labels, \"Otros\")\n",
    "\n",
    "df_unlabeled[\"category\"] = final_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d08aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_labeled, df_unlabeled], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65df5266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Política y Sociedad          143466\n",
       "Entretenimiento y Cultura     65832\n",
       "Tecnología y Ciencia          40355\n",
       "Otros                         32472\n",
       "Humor y Memes                  3023\n",
       "Deportes                        890\n",
       "Negocios y Economía             306\n",
       "Historia y Humanidades          306\n",
       "Crimen                          256\n",
       "Transporte                      222\n",
       "Medioambiente y Energía         200\n",
       "Salud y Medicina                139\n",
       "Cuestiones Sociales              69\n",
       "Educación                        27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ba41b-326f-4568-9b3b-fadbcbb32e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_type(df):\n",
    "    df = df.astype({\n",
    "        \"meneos\": \"uint16\",\n",
    "        \"karma\": \"uint16\",\n",
    "        \"positive_votes\": \"uint16\",\n",
    "        \"negative_votes\": \"uint16\",\n",
    "        \"anonymous_votes\": \"uint16\",\n",
    "        \"comments\": \"uint16\",\n",
    "        \"clicks\": \"int32\",\n",
    "        \"category\": \"category\",\n",
    "        \"provincia\": \"category\",\n",
    "        \"comunidad\": \"category\"\n",
    "    })\n",
    "\n",
    "    df[\"published_date\"] = pd.to_datetime(df[\"published_date\"], errors=\"coerce\")\n",
    "    df[\"scraped_date\"] = pd.to_datetime(df[\"scraped_date\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d58159",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000\n",
    "num_chunks = (len(df_final) // chunk_size) + 1\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_row = i * chunk_size\n",
    "    end_row = start_row + chunk_size\n",
    "    df_chunk = df_final.iloc[start_row:end_row]\n",
    "\n",
    "    file_name = f\"../00.data/preprocesado/meneame_procesado_{i+1}.pkl\"\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        pickle.dump(df_chunk, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Guardado: {file_name} con {len(df_chunk)} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with gzip.open(\"../00.data/preprocesado/meneame_procesado.pkl.gz\", \"wb\") as f:\n",
    "#    pickle.dump(df_final, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f0e31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
