import streamlit as st
import pickle
import os
import pandas as pd
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
import sys
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import seaborn as sns
import plotly.figure_factory as ff

load_dotenv()

user = os.getenv("user")
sys.path.append(f"/Users/{user}/Analisis-de-noticias/src")

from utils.clustering import Clustering

st.title("Machine Learning en Men√©ame")

# üîπ Introductory Section
st.markdown("""
### üîç Predicci√≥n de Clicks en Noticias Antiguas

En la plataforma Men√©ame, hay noticias publicadas antes del a√±o 2010 que **no tienen registros de clicks**.  
El objetivo de esta secci√≥n es mostrar el proceso de **predecir la cantidad de clicks** para estas noticias utilizando **t√©cnicas de Machine Learning**.  

Para lograrlo, hemos aplicado distintos modelos de **Clustering, Clasificaci√≥n y Regresi√≥n**, que puedes explorar a continuaci√≥n.
""")

# üîπ Subpage Navigation
subpage = st.radio("Selecciona un an√°lisis:", ["Clustering", "Clasificaci√≥n", "Regresi√≥n", "Predicci√≥n de Noticias"])

if subpage == "Clustering":
    st.subheader("üîç Clustering")
    st.write("Aqu√≠ mostramos los resultados del an√°lisis de Clustering.")

    clustering = Clustering()

    # Initialize session state for storing figures
    if "elbow_chart" not in st.session_state:
        st.session_state.elbow_chart = None
    if "barplot" not in st.session_state:
        st.session_state.barplot = None
    if "heatmap" not in st.session_state:
        st.session_state.heatmap = None

    # Generate and store Elbow Chart
    if st.button("Generar Elbow Chart"):
        st.session_state.elbow_chart = clustering.generate_elbow_chart()  # üîπ Properly indented

    # Display stored Elbow Chart
    if st.session_state.elbow_chart:
        st.pyplot(st.session_state.elbow_chart)

    # Select number of clusters
    n_clusters = st.slider("Selecciona el n√∫mero de clusters:", min_value=2, max_value=10, value=3, step=1)

    # Generate and store Barplot
    if st.button("Generar Barplots para Clusters"):
        fig, ax = plt.subplots(figsize=(15, 10))
        clustering.apply_kmeans(n_clusters)
        clustering.df_numeric.groupby(f"cluster_{n_clusters}")[['karma', 'clicks', 'negative_votes', 
                                                                'positive_votes', 'anonymous_votes', 
                                                                'meneos', 'comments']].mean().T.plot(kind='bar', ax=ax)

        plt.title(f"Mean of Each Numeric Variable by Cluster ({n_clusters} Clusters)")
        plt.xlabel("Variables")
        plt.ylabel("Mean Value")
        plt.xticks(rotation=45)

        cluster_names = {
            0: "Noticias bien recibidas",
            1: "Noticias pol√©micas",
            2: "Noticias est√°ndar"
        }

        # Update legend labels
        handles, labels = plt.gca().get_legend_handles_labels()
        custom_labels = [cluster_names.get(int(label), label) for label in labels]
        plt.legend(handles, custom_labels, title="Cluster")

        st.session_state.barplot = fig

    # Display stored Barplot
    if st.session_state.barplot:
        st.pyplot(st.session_state.barplot)

    # Generate and store Heatmap
    if st.button("Generar Heatmap de Categor√≠as por Cluster"):
        fig = clustering.plot_heatmap(n_clusters)
        if fig:
            st.session_state.heatmap = fig
        else:
            st.warning("No hay datos suficientes para generar el heatmap.")

    # Display stored Heatmap
    if st.session_state.heatmap:
        st.pyplot(st.session_state.heatmap)

elif subpage == "Clasificaci√≥n":
    # Definir ruta de datos
    DATA_PATH = "src/00.data/clustering"

    st.subheader("üéØ Clasificaci√≥n")
    st.write("Aqu√≠ mostramos los resultados del an√°lisis de Clasificaci√≥n.")


    # Cargar archivos necesarios
    def load_pickle(file_path):
        """Carga un archivo pickle si existe, sino devuelve None."""
        try:
            with open(file_path, "rb") as f:
                return pickle.load(f)
        except FileNotFoundError:
            st.error(f"‚ùå No se encontr√≥ el archivo `{file_path}`.")
            return None

    # Cargar datos
    y_test = load_pickle(os.path.join(DATA_PATH, "y_test.pkl"))
    y_pred = load_pickle(os.path.join(DATA_PATH, "y_pred.pkl"))
    cm = load_pickle(os.path.join(DATA_PATH, "confusion_matrix.pkl"))
    df_numeric = load_pickle(os.path.join(DATA_PATH, "df_numeric.pkl"))
    cluster_counts = load_pickle(os.path.join(DATA_PATH, "cluster_counts.pkl"))
    df_cluster_means = load_pickle(os.path.join(DATA_PATH, "df_cluster_means.pkl"))
    cluster_category_pct = load_pickle(os.path.join(DATA_PATH, "cluster_category_pct.pkl"))

    # Distribuci√≥n de Noticias por Cluster
    if cluster_counts is not None:
        st.markdown("### üìå Distribuci√≥n de Noticias por Cluster")

        fig, ax = plt.subplots()
        cluster_counts.plot(kind="bar", color=["red", "blue", "green"], ax=ax)
        ax.set_xticks(range(len(cluster_counts.index)))
        ax.set_xticklabels(cluster_counts.index, rotation=45)
        ax.set_ylabel("Cantidad de Noticias")
        ax.set_title("Distribuci√≥n de Noticias por Cluster")

        st.pyplot(fig)

    # Caracter√≠sticas Promedio por Cluster
    if df_cluster_means is not None:
        st.markdown("### üìä Caracter√≠sticas Promedio por Cluster")
        st.dataframe(df_cluster_means.style.format("{:.2f}"))

    # Explicaci√≥n de los Clusters
    st.markdown("### üîé Explicaci√≥n de los Clusters")
    st.write("""
    #### Cluster 0 ‚Üí Noticias Pol√©micas o Virales üî•  
    - Menos numeroso, pero con la media m√°s alta de **clicks**, **votos an√≥nimos** y **comentarios**.  
    - Genera una gran interacci√≥n, pero tambi√©n es el grupo con m√°s **votos negativos**.  

    #### Cluster 1 ‚Üí Noticias Est√°ndar üì∞  
    - Es el cluster m√°s numeroso con gran diferencia.  
    - Tiene el menor n√∫mero de **meneos y clicks**, un **karma medio** y los **votos positivos y negativos m√°s bajos**.  
    - Recibe la menor cantidad de **comentarios**, lo que sugiere menor interacci√≥n.  

    #### Cluster 2 ‚Üí Noticias Bien Recibidas üåü  
    - Recibe la mayor cantidad de **meneos** y tiene el **karma m√°s alto**.  
    - Los **votos positivos y an√≥nimos** son los m√°s altos, con una cantidad significativa de **comentarios**.  
    - Representa las noticias populares y apreciadas dentro de la comunidad.  
    """)

    # Distribuci√≥n de Categor√≠as por Cluster (%)
    if cluster_category_pct is not None:
        st.markdown("### üìä Distribuci√≥n de Categor√≠as por Cluster (%)")

        fig, ax = plt.subplots(figsize=(12, 6))
        sns.heatmap(cluster_category_pct, cmap="coolwarm", annot=True, fmt=".1f", linewidths=0.5, ax=ax)
        ax.set_title("Distribuci√≥n de Categor√≠as por Cluster (%)")
        ax.set_ylabel("Cluster")
        ax.set_xlabel("Categor√≠a")

        st.pyplot(fig)

    # Matriz de Confusi√≥n
    if cm is not None:
        st.markdown("### üî• Matriz de Confusi√≥n")
        labels = ["Cluster 0 - Noticias pol√©micas", "Cluster 1 - Noticias est√°ndar",
                  "Cluster 2 - Noticias bien recibidas"]

        fig = ff.create_annotated_heatmap(
            z=cm,
            x=labels,
            y=labels,
            colorscale="Blues",
            showscale=True
        )

        fig.update_layout(title="Matriz de Confusi√≥n", xaxis=dict(title="Predicho"), yaxis=dict(title="Real"))
        st.plotly_chart(fig, use_container_width=True)

    # Reporte de Clasificaci√≥n
    if y_test is not None and y_pred is not None:
        st.markdown("### üìä Reporte de Clasificaci√≥n")
        report_dict = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report_dict).transpose()
        st.dataframe(report_df.style.format({"precision": "{:.2f}", "recall": "{:.2f}", "f1-score": "{:.2f}"}))

elif subpage == "Regresi√≥n":
    st.subheader("üìä An√°lisis de Regresi√≥n")
    st.write("Aqu√≠ mostramos los resultados del an√°lisis de regresi√≥n aplicada a los clicks en Men√©ame.")

    # üìå Definir ruta de datos
    DATA_PATH = "src/00.data/clustering"


    # üìå Funci√≥n para cargar archivos pickle
    def load_pickle(file_path):
        """Carga un archivo pickle si existe, sino devuelve None."""
        try:
            with open(file_path, "rb") as f:
                return pickle.load(f)
        except FileNotFoundError:
            st.error(f"‚ùå No se encontr√≥ el archivo `{file_path}`.")
            return None


    # üìå Cargar los archivos necesarios
    metrics_df = load_pickle(os.path.join(DATA_PATH, "metrics_df.pkl"))
    resultados = load_pickle(os.path.join(DATA_PATH, "correlacion_clicks.pkl"))
    comparacion_datasets = load_pickle(os.path.join(DATA_PATH, "comparacion_datasets.pkl"))

    # M√©tricas de Modelos
    st.header("M√©tricas de los Modelos")
    st.dataframe(metrics_df)

    # Explicaci√≥n de los resultados
    st.header("üìå Explicaci√≥n de los Resultados")

    st.markdown("""
    - üìâ **Los modelos explican poco la variabilidad de clicks** debido a la baja R¬≤.
    - üßê **Posibles razones:** Variables no consideradas como la hora, d√≠a, semana, mes de publicaci√≥n, fuente de la noticia, etc.
    - ‚ö†Ô∏è **Errores altos:** Median AE y MAE son elevados en todos los modelos.
    - üèÜ **Mejor modelo:** Gradient Boosting Regressor destaca en todos los casos.

    **An√°lisis por cluster:**
    - ‚úÖ **Cluster 1 (Noticias est√°ndar)**: M√°s f√°cil de predecir, con errores m√°s bajos y mejor R¬≤.
    - üî• **Cluster 0 (Noticias pol√©micas o virales)**: Mayor error de predicci√≥n (Median AE y MAE m√°s altos).
    - ü§î **Cluster 2 (Noticias bien recibidas)**: Errores intermedios entre Cluster 0 y 1.

    **Pr√≥ximos pasos:**
    - üìå Probar **Redes Neuronales**.
    - üõ†Ô∏è Explorar **nuevas variables** y mejorar Feature Engineering.
    """)

    # üìà An√°lisis de Correlaci√≥n con Clicks
    st.header("üìà An√°lisis de Correlaci√≥n con Clicks")

    # Selector de cluster
    cluster_seleccionado = st.selectbox("Selecciona un cluster:", list(resultados.keys()))

    # Extraer el gr√°fico de correlaci√≥n del cluster seleccionado
    fig_corr = resultados[cluster_seleccionado]["fig_corr"]

    # Mostrar el gr√°fico interactivo de correlaci√≥n con Plotly
    st.subheader(f"üîç Correlaci√≥n de Variables con Clicks - Cluster {cluster_seleccionado}")
    st.plotly_chart(fig_corr, use_container_width=True)

    # Comparaci√≥n antes y despu√©s del modelo
    st.header("üìä Comparaci√≥n del Dataset Antes y Despu√©s del Modelo")

    comparacion_datasets = load_pickle(os.path.join(DATA_PATH, "comparacion_datasets.pkl"))

    if comparacion_datasets is not None:
        # Opciones del desplegable
        opciones_graficos = {
            "Promedio de Clicks por Cluster": "fig_cluster",
            "Promedio de Clicks por Categor√≠a": "fig_category",
            "Boxplot de Clicks": "fig_box",
            "Histograma de Clicks": "fig_hist"
        }

        # Desplegable para seleccionar gr√°fico
        seleccion = st.selectbox(
            "üìä Selecciona el gr√°fico que quieres ver:",
            list(opciones_graficos.keys()),
            index=0  # Por defecto se muestra "Promedio de Clicks por Cluster"
        )

        # üìå Mostrar el gr√°fico seleccionado
        st.plotly_chart(comparacion_datasets[opciones_graficos[seleccion]], use_container_width=True)
    else:
        st.error("‚ùå No se encontr√≥ el archivo `comparacion_datasets.pkl`.")


elif subpage == "Predicci√≥n de Noticias":
    st.subheader("üîÆ Predicci√≥n de Noticias")
    st.write("Introduce los valores de una noticia y descubre a qu√© cluster pertenecer√≠a.")

    load_dotenv()

    def get_engine():
        user = os.getenv("DB_USER")
        password = os.getenv("DB_PASSWORD")
        host = os.getenv("HOST", "localhost")
        database = "meneame"
        return create_engine(f"mysql+pymysql://{user}:{password}@{host}/{database}")

    engine = get_engine()

    query = text("""
            SELECT 
                COALESCE(MAX(meneos), 0) AS max_meneos,
                COALESCE(MAX(karma), 0) AS max_karma,
                COALESCE(MAX(positive_votes), 0) AS max_positive_votes,
                COALESCE(MAX(anonymous_votes), 0) AS max_anonymous_votes,
                COALESCE(MAX(negative_votes), 0) AS max_negative_votes,
                COALESCE(MAX(comments), 0) AS max_comments
            FROM news_info_table;
    """)

    # Ejecutar la consulta y obtener los valores
    with engine.connect() as conn:
        result = conn.execute(query).fetchone()

    # Inicializamos valores en 0
    max_meneos, max_karma, max_positive_votes, max_anonymous_votes, max_negative_votes, max_comments = result or (
    0, 0, 0, 0, 0, 0)

    # Configurar sliders en Streamlit con m√≠nimo en 0 y m√°ximo desde SQL
    meneos = st.slider("Meneos", min_value=0, max_value=max_meneos, value=0)
    karma = st.slider("Karma", min_value=0, max_value=max_karma, value=0)
    positive_votes = st.slider("Votos positivos", min_value=0, max_value=max_positive_votes, value=0)
    anonymous_votes = st.slider("Votos an√≥nimos", min_value=0, max_value=max_anonymous_votes, value=0)
    negative_votes = st.slider("Votos negativos", min_value=0, max_value=max_negative_votes, value=0)
    comments = st.slider("Comentarios", min_value=0, max_value=max_comments, value=0)

    # Selecci√≥n de categor√≠a
    CATEGORIAS_FIJAS = [
        'Crimen', 'Cuestiones Sociales', 'Deportes', 'Educaci√≥n', 'Entretenimiento y Cultura',
        'Historia y Humanidades', 'Humor y Memes', 'Medioambiente y Energ√≠a',
        'Negocios y Econom√≠a', 'Otros', 'Pol√≠tica y Sociedad', 'Salud y Medicina',
        'Tecnolog√≠a y Ciencia', 'Transporte'
    ]
    categoria = st.selectbox("Categor√≠a", CATEGORIAS_FIJAS)

    # Bot√≥n para hacer la predicci√≥n
    if st.button("Predecir Cluster y Clicks"):
        from utils.prediccion_cluster import predecir_cluster  # Importar la funci√≥n
        from utils.prediccion_regresion import predecir_clicks  # Importar la funci√≥n de regresi√≥n

        # **1Ô∏è‚É£ Predecir Cluster**
        cluster_predicho = predecir_cluster(meneos, karma, positive_votes, anonymous_votes, negative_votes, comments,
                                            categoria)

        CLUSTER_SIGNIFICADO = {
            0: "Noticias pol√©micas o virales",
            1: "Noticias est√°ndar",
            2: "Noticias bien recibidas"
        }

        # **2Ô∏è‚É£ Predecir Clicks usando el Cluster obtenido**
        predicted_clicks = predecir_clicks(meneos, karma, positive_votes, anonymous_votes, negative_votes, comments,
                                           categoria, cluster_predicho)

        # **3Ô∏è‚É£ Mostrar los resultados**
        st.success(
            f"La noticia pertenece al cluster: **{CLUSTER_SIGNIFICADO[cluster_predicho]}** (Cluster {cluster_predicho})")
        st.markdown(f"üîÆ Se estima que la noticia recibir√° aproximadamente **{int(predicted_clicks):,} clicks**.")